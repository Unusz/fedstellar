import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy("file_system")

import torch.nn as nn
import pytorch_lightning as pl
from torchmetrics import MeanSquaredError
from pytorch_lightning import Trainer
import numpy as np

# for testing
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
import pandas as pd
from torchmetrics import Accuracy, Precision, Recall, F1Score, MetricCollection
from torchmetrics.classification import BinaryConfusionMatrix
import seaborn as sns
import matplotlib.pyplot as plt


class MalwaresModelAutoencoder(pl.LightningModule):

    def __init__(
            self,
            input_dim=100,
            metrics=None,
            confusion_matrix=None,
            seed=None
    ):
        super().__init__()
        # Encoder layer
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.BatchNorm1d(32),
            nn.GELU(),
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.GELU()

        )
        # Decoder layer
        self.decoder = nn.Sequential(
            nn.Linear(16, 32),
            nn.BatchNorm1d(32),
            nn.GELU(),
            nn.Linear(32, input_dim),
            nn.GELU()
        )

        self.reconstruction_error = MeanSquaredError()
        self.sum_errors = 0
        self.total_samples = 0
        self.sum_squared_differences_from_mean = 0
        self.train_reconstruction_error_mean = 0
        self.train_reconstruction_error_variance = 0
        self.anomaly_threshold = 0
        self.test_accuracy = Accuracy(num_classes=2, task='binary')
        self.test_precision = Precision(num_classes=2, task='binary')
        self.test_recall = Recall(num_classes=2, task='binary')
        self.test_f1 = F1Score(num_classes=2, task='binary')
        self.predictions = []
        self.labels_list = []
        self.inputs_list = []
        
        if metrics is None:
            metrics = MetricCollection([
                Accuracy(num_classes=2, task='binary'),
                Precision(num_classes=2, task='binary'),
                Recall(num_classes=2, task='binary'),
                F1Score(num_classes=2, task='binary')
            ])

        # Define metrics
        self.test_metrics = metrics.clone(prefix="Test/")

        if confusion_matrix is None:
            self.cm = BinaryConfusionMatrix()

        # Set seed for reproducibility initialization
        if seed is not None:
            torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.001)


    def training_step(self, batch, batch_idx):
        inputs, _ = batch
        outputs = self.forward(inputs)
        loss = self.reconstruction_error(outputs, inputs)
        
        self.log("Train/Loss", loss, prog_bar=True)

        batch_errors = (outputs - inputs).pow(2).sum(dim=1)
        self.sum_errors += batch_errors.sum()
        self.total_samples += inputs.size(0)

        return loss


    def on_train_epoch_end(self, unused=None):
        # Calculate mean
        mean_reconstruction_error = self.sum_errors / self.total_samples

        # Accumulate squared differences from the mean for variance
        for batch in self.trainer.train_dataloader:
            inputs, _ = batch
            outputs = self.forward(inputs)
            reconstruction_error = (outputs - inputs).pow(2).sum(dim=1)
            self.sum_squared_differences_from_mean += ((reconstruction_error - mean_reconstruction_error).pow(2)).sum()


        # Calculate variance
        variance_reconstruction_error = self.sum_squared_differences_from_mean / self.total_samples

        self.train_reconstruction_error_mean = mean_reconstruction_error
        self.train_reconstruction_error_variance = variance_reconstruction_error
        self.anomaly_threshold = self.train_reconstruction_error_mean + torch.sqrt(self.train_reconstruction_error_variance)

        # Reset accumulators
        self.sum_errors = 0
        self.sum_squared_differences_from_mean = 0
        self.total_samples = 0

    def validation_step(self, batch, batch_idx):
        inputs, _ = batch
        outputs = self.forward(inputs)
        loss = self.reconstruction_error(outputs, inputs)
        self.log("Validation/Loss", loss, prog_bar=True)

        return loss
    
    def test_step(self, batch, batch_idx):
        inputs, batch_labels = batch
        outputs = self.forward(inputs)
        loss = self.reconstruction_error(outputs, inputs)
        
        self.log("Test/Loss", loss, prog_bar=True)

        # Anomaly detection
        batch_reconstruction_error = (outputs - inputs).pow(2).sum(dim=1)
        anomalies = (batch_reconstruction_error > self.anomaly_threshold).int()

        # Update metrics
        self.test_accuracy.update(anomalies, batch_labels.int())
        self.test_precision.update(anomalies, batch_labels.int())
        self.test_recall.update(anomalies, batch_labels.int())
        self.test_f1.update(anomalies, batch_labels.int())
        
        self.cm.update(anomalies, batch_labels.int())

        # Store data for later use
        self.predictions.append(anomalies)
        self.labels_list.append(batch_labels)
        self.inputs_list.append(inputs)

        return loss

    def on_test_epoch_end(self):
        # Log metrics
        self.log("Test/Accuracy", self.test_accuracy.compute())
        self.log("Test/Precision", self.test_precision.compute())
        self.log("Test/Recall", self.test_recall.compute())
        self.log("Test/F1", self.test_f1.compute())

        # Reset metrics
        self.test_accuracy.reset()
        self.test_precision.reset()
        self.test_recall.reset()
        self.test_f1.reset()
        
        cm = self.cm.compute().cpu()
        print("TestEpoch/CM\n", cm)   
        plt.figure(figsize=(10, 7))
        ax = sns.heatmap(cm.numpy(), annot=True, fmt="d", cmap="Blues")
        ax.set_xlabel("Predicted labels")
        ax.set_ylabel("True labels")
        ax.set_title("Confusion Matrix")
        ax.set_xticks(range(2))
        ax.set_yticks(range(2))
        ax.xaxis.set_ticklabels([i for i in range(2)])
        ax.yaxis.set_ticklabels([i for i in range(2)])
        self.logger.experiment.add_figure("TestEpoch/CM", ax.get_figure())
        plt.close()

        # Convert lists to tensors and then to numpy arrays
        predictions = torch.cat(self.predictions).numpy()
        batch_labels = torch.cat(self.labels_list).numpy()
        inputs = torch.cat(self.inputs_list).numpy()

        # Save to file
        results_df = pd.DataFrame(inputs, columns=[f'feature_{i}' for i in range(inputs.shape[1])])
        results_df['True_Label'] = batch_labels
        results_df['Prediction'] = predictions
        results_df.to_csv('test_results.csv', index=False)