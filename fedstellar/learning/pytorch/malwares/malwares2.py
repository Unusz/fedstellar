import os
import sys

# To Avoid Crashes with a lot of nodes
import torch.multiprocessing
from torch.utils.data import Dataset, TensorDataset
import pandas as pd
from sklearn.model_selection import train_test_split

torch.multiprocessing.set_sharing_strategy("file_system")


class MalwaresDataset2(Dataset):
    """
    Args:
        sub_id: Subset id of partition. (0 <= sub_id < number_sub)
        number_sub: Number of subsets.
        batch_size: The batch size of the data.
        num_workers: The number of workers of the data.
        val_percent: The percentage of the validation set.
    """

    def __init__(
            self,
            root_dir="./data",
            sub_id=0,
            number_sub=1,
            batch_size=64,
            num_workers=4,
            val_percent=0.1,
            iid=True,
    ):
        super().__init__()
        self.root_dir = root_dir
        self.sub_id = sub_id
        self.number_sub = number_sub
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.val_percent = val_percent
        self.iid = iid
            
        self.train_set, self.test_set = self.load_data()
        
            
    def load_data(self):
        # Load and prepare your data
        csv_path = os.path.join(self.root_dir, 'data_20s_final.csv')
        data_csv = pd.read_csv(csv_path)
        labels = data_csv.iloc[:, 0].apply(lambda x: 0 if x == 0 else 1)
        features = data_csv.iloc[:, 1:]
        
        # Split the data
        train_data, test_data_normal, train_labels, test_labels_normal = train_test_split(features[labels == 0], labels[labels == 0], test_size=0.20, random_state=42)
        
        # Combine test data
        test_data = pd.concat([test_data_normal, features[labels != 0]])
        test_labels = pd.concat([test_labels_normal, labels[labels != 0]])
        
        # Convert to TensorDatasets
        train_dataset = TensorDataset(torch.tensor(train_data.values, dtype=torch.float32), torch.tensor(train_labels.values, dtype=torch.float32))
        test_dataset = TensorDataset(torch.tensor(test_data.values, dtype=torch.float32), torch.tensor(test_labels.values, dtype=torch.float32))

        
        return train_dataset, test_dataset