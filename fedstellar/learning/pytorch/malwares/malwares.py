import os
import sys

# To Avoid Crashes with a lot of nodes
import torch.multiprocessing
from torch.utils.data import Dataset, TensorDataset
import pandas as pd
from sklearn.model_selection import train_test_split

torch.multiprocessing.set_sharing_strategy("file_system")


class MalwaresDataset(Dataset):
    """
    Args:
        sub_id: Subset id of partition. (0 <= sub_id < number_sub)
        number_sub: Number of subsets.
        batch_size: The batch size of the data.
        num_workers: The number of workers of the data.
        val_percent: The percentage of the validation set.
    """

    def __init__(
            self,
            root_dir="./data",
            sub_id=0,
            number_sub=1,
            batch_size=32,
            num_workers=4,
            val_percent=0.1,
            iid=True,
    ):
        super().__init__()
        self.root_dir = root_dir
        self.sub_id = sub_id
        self.number_sub = number_sub
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.val_percent = val_percent
        self.iid = iid
            
        self.train_set, self.test_set = self.load_data()
        
            
    def load_data(self):
        csv_path = os.path.join(self.root_dir, 'data_20s_final.csv')
        data_frame = pd.read_csv(csv_path)
        
        labels = torch.tensor(data_frame.iloc[:, 0].values, dtype=torch.long)
        features = torch.tensor(data_frame.iloc[:, 1:].values, dtype=torch.float32)
        
        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

        train = TensorDataset(X_train, y_train)
        test = TensorDataset(X_test, y_test)
        
        return train, test
    
